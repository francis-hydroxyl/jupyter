{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "english-marker",
   "metadata": {
    "id": "english-marker"
   },
   "outputs": [],
   "source": [
    "# 標準ライブラリ\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# データ操作・数値計算ライブラリ\n",
    "import numpy as np\n",
    "import cv2\n",
    "import scipy.ndimage\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "# PyTorch関連\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchsummary import summary\n",
    "\n",
    "# 天文学・画像処理ライブラリ\n",
    "import astropy.io.fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from photutils.detection import DAOStarFinder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# W&B (Weights & Biases)\n",
    "import wandb\n",
    "\n",
    "# NpyAppendArray\n",
    "from npy_append_array import NpyAppendArray\n",
    "\n",
    "# tqdm (プログレスバー)\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.resetwarnings()\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chief-toddler",
   "metadata": {
    "id": "chief-toddler"
   },
   "outputs": [],
   "source": [
    "# プロジェクト固有モジュール\n",
    "# ユーザーの環境に合わせてパスを設定\n",
    "sys.path.append('/home/elmegreen/galactic_bubble/photoutils/')\n",
    "from utils.ssd_model import SSD, Detect\n",
    "from utils.ssd_predict_show import SSDPredictShow\n",
    "# from processing import conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "930ba161-729a-4d03-b0cb-3b464c894365",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_nan(data1):\n",
    "\n",
    "    mask1_10 = data1 == data1\n",
    "    mask1_1010 = np.where(mask1_10, 0, 1)\n",
    "    label1, name1 = scipy.ndimage.label(mask1_1010)\n",
    "    data_areas1 = scipy.ndimage.sum(mask1_1010, label1, np.arange(name1 + 1))\n",
    "    minsize1 = 500\n",
    "    data_mask1_10 = (data_areas1 < minsize1) & (0 < data_areas1)\n",
    "    small_mask1_10 = data_mask1_10[label1.ravel()].reshape(label1.shape)\n",
    "    data1[small_mask1_10] = np.nanmax(data1)\n",
    "\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aabcf28-3890-4f58-8f43-a57040a08cc7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_lognormal_component(data):\n",
    "    \"\"\"\n",
    "    データから対数正規成分をフィッティングして統計値を取得\n",
    "    \"\"\"\n",
    "    # NaNを除去し、正の値のみを使用\n",
    "    clean_data = data[~np.isnan(data) & (data > 0)]\n",
    "    \n",
    "    if len(clean_data) < 10:  # データが少なすぎる場合\n",
    "        warnings.warn(\"データが少なすぎるため、通常の統計値を使用します\")\n",
    "        return np.nanmean(data), np.nanstd(data)\n",
    "    \n",
    "    try:\n",
    "        # 対数正規分布のパラメータをフィッティング\n",
    "        # lognormのパラメータ: s(shape), loc(location), scale\n",
    "        params = lognorm.fit(clean_data, floc=0)  # locationを0に固定\n",
    "        s, loc, scale = params\n",
    "        \n",
    "        # 対数正規分布の統計値を計算\n",
    "        lognorm_mean = lognorm.mean(s, loc=loc, scale=scale)\n",
    "        lognorm_std = lognorm.std(s, loc=loc, scale=scale)\n",
    "        \n",
    "        return lognorm_mean, lognorm_std\n",
    "        \n",
    "    except Exception as e:\n",
    "        warnings.warn(f\"対数正規分布のフィッティングに失敗: {e}. 通常の統計値を使用します\")\n",
    "        return np.nanmean(clean_data), np.nanstd(clean_data)\n",
    "\n",
    "def norm_rp_improved(data, nan_data_dim=None, use_lognormal=True, min_method='std'):\n",
    "    \"\"\"\n",
    "    改良された正規化関数\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : numpy.ndarray\n",
    "        正規化するデータ\n",
    "    nan_data_dim : numpy.ndarray, optional\n",
    "        統計値計算用の参照データ（Noneの場合はdataを使用）\n",
    "    use_lognormal : bool, default=True\n",
    "        対数正規分布を使用するかどうか\n",
    "    min_method : str, default='std'\n",
    "        最小値の決定方法 ('min', 'std', '2std')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        正規化されたデータ\n",
    "    \"\"\"\n",
    "    # 参照データの決定\n",
    "    ref_data = nan_data_dim if nan_data_dim is not None else data\n",
    "    \n",
    "    if use_lognormal:\n",
    "        # 対数正規成分から統計値を取得\n",
    "        mean, std = fit_lognormal_component(ref_data)\n",
    "    else:\n",
    "        # 従来の方法（ガウス分布仮定）\n",
    "        mean = np.nanmean(ref_data)\n",
    "        std = np.nanstd(ref_data)\n",
    "    \n",
    "    # 最大値の計算（3σルール）\n",
    "    max_val = mean + 3 * std\n",
    "    \n",
    "    # 最小値の決定\n",
    "    if min_method == 'min':\n",
    "        min_val = np.nanmin(ref_data)\n",
    "    elif min_method == 'std':\n",
    "        min_val = mean - std\n",
    "    elif min_method == '2std':\n",
    "        min_val = mean - 2 * std\n",
    "    else:\n",
    "        raise ValueError(\"min_method must be 'min', 'std', or '2std'\")\n",
    "    \n",
    "    # 最大値が小さすぎる場合の対処\n",
    "    if max_val < 0.5:\n",
    "        max_val = 0.5\n",
    "    \n",
    "    # 最小値がデータの最小値より大きくなりすぎないように調整\n",
    "    data_min = np.nanmin(ref_data)\n",
    "    if min_val > data_min + (max_val - data_min) * 0.5:\n",
    "        min_val = data_min\n",
    "    \n",
    "    # 正規化の実行\n",
    "    data_normalized = data.copy()\n",
    "    data_normalized -= min_val\n",
    "    data_normalized /= (max_val - min_val)\n",
    "    \n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcacb0a9-2e8c-46ac-8779-9d9032b8e82a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def norm_rp(data, nan_data_dim=None):\n",
    "    if nan_data_dim is not None:\n",
    "        data_min = np.nanmin(nan_data_dim)\n",
    "        std = np.nanstd(nan_data_dim)\n",
    "        mean = np.nanmean(nan_data_dim)\n",
    "        max_ = mean + 3 * std\n",
    "    else:\n",
    "        data_min = np.nanmin(data)\n",
    "        std = np.nanstd(data)\n",
    "        mean = np.nanmean(data)\n",
    "        max_ = mean + 3 * std\n",
    "\n",
    "    # if max_ < 0.5:\n",
    "    #     max_ = 0.5\n",
    "    data -= data_min\n",
    "    data /= max_\n",
    "    return data\n",
    "\n",
    "\n",
    "def normalize_rp(array, r_header, g_header):\n",
    "    \"\"\"\n",
    "    Input : (y, x, 2 or 3)\n",
    "    Output: (y ,x, 2 or 3)\n",
    "    \"\"\"\n",
    "    gauss_list = []\n",
    "    dims = array.shape[2]\n",
    "    for dim in range(dims):\n",
    "        cut_data_k = array[:, :, dim]\n",
    "        if dim == 0 or dim == 2:\n",
    "            # cut_data_k_ = norm_rp(cut_data_k)\n",
    "            cut_data_k_ = norm_rp_improved(cut_data_k)\n",
    "            gauss_list.append(cut_data_k_[:, :, None])\n",
    "        else:\n",
    "            nan_data = remove_peak(cut_data_k, dim, r_header, g_header)\n",
    "            # cut_data_k_ = norm_rp(cut_data_k, nan_data)\n",
    "            cut_data_k_ = norm_rp_improved(cut_data_k, nan_data)\n",
    "            gauss_list.append(cut_data_k_[:, :, None])\n",
    "    cut_data = np.concatenate(gauss_list, axis=2)\n",
    "\n",
    "    return cut_data\n",
    "\n",
    "\n",
    "def remove_peak(array, dim, r_resolution, g_resolution):\n",
    "    data = array.copy()\n",
    "    mean, median, std = sigma_clipped_stats(data, sigma=3)\n",
    "    if dim == 0:\n",
    "        # fwhm_arcsec = 0.674\n",
    "        fwhm_arcsec = 0.7\n",
    "        fwhm_pixel = fwhm_arcsec / r_resolution\n",
    "    elif dim == 1:\n",
    "        # fwhm_arcsec = 0.269\n",
    "        fwhm_arcsec = 0.3\n",
    "        fwhm_pixel = fwhm_arcsec / g_resolution\n",
    "\n",
    "    daofind = DAOStarFinder(fwhm=abs(fwhm_pixel), threshold=mean + 3 * std)\n",
    "    sources = daofind(data)\n",
    "    try:\n",
    "        positions = np.transpose((sources[\"xcentroid\"], sources[\"ycentroid\"]))\n",
    "        same_shape_zero = np.zeros_like(data)\n",
    "        for y, x in positions:\n",
    "            same_shape_zero = cv2.circle(same_shape_zero, (int(y), int(x)), int(4), (255, 255, 255), -1)\n",
    "\n",
    "        data[same_shape_zero == same_shape_zero.max()] = np.nan\n",
    "        return data\n",
    "    except:\n",
    "        return data\n",
    "\n",
    "\n",
    "def resize(data, size):\n",
    "    \"\"\"\n",
    "    Resize data to the specified size.\n",
    "\n",
    "    Input  :（y, x, 2 or 3）\n",
    "    Output :（size ,size, 2 or 3）\n",
    "    \"\"\"\n",
    "    cut_data = np.swapaxes(data, 1, 2)\n",
    "    cut_data = np.swapaxes(cut_data, 0, 1)\n",
    "    cut_data = torch.from_numpy(cut_data)\n",
    "    cut_data = cut_data.unsqueeze(0)\n",
    "    resize_data = F.interpolate(cut_data, (size, size), mode=\"bilinear\", align_corners=False)\n",
    "    resize_data = np.squeeze(resize_data.detach().numpy())\n",
    "\n",
    "    resize_data_ = np.swapaxes(resize_data, 0, 1)\n",
    "    resize_data_ = np.swapaxes(resize_data_, 1, 2)\n",
    "    return resize_data_\n",
    "\n",
    "\n",
    "def norm_res(data, r_header, g_header):\n",
    "    \"\"\"\n",
    "    Cuts the data,\n",
    "    and performs normalization and resizing.\n",
    "    \"\"\"\n",
    "    # shape_y = data.shape[0]\n",
    "    # shape_x = data.shape[1]\n",
    "    # data = data[int(shape_y / 4) : int(shape_y * 3 / 4), int(shape_x / 4) : int(shape_x * 3 / 4)]\n",
    "    data_ = copy.deepcopy(data)\n",
    "    data_ = normalize_rp(data_, r_header, g_header)\n",
    "    data_ = resize(data_, 300)\n",
    "\n",
    "    return data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a82b85e-a599-40b6-b30c-174fc28f1207",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def conv(obj_size, obj_sig, data):\n",
    "    \"\"\"\n",
    "    Input size of data↓\n",
    "    Input: (y, x, 2 or 3)\n",
    "    Output: (size, size, 2 or 3)\n",
    "    -------------------------------\n",
    "    If the cut-out data is larger than obj_size, perform smoothing.\n",
    "    If it's smaller, return it as is.\n",
    "    \"\"\"\n",
    "    if data.shape[0] > obj_size*1.1:\n",
    "        fwhm = (data.shape[0] / obj_size) * 2\n",
    "        sig3 = fwhm / (2 * (2 * np.log(2)) ** (1 / 2))\n",
    "        if sig3 > obj_sig:\n",
    "            sig2 = (sig3**2 - obj_sig**2) ** (1 / 2)        \n",
    "            kernel = np.outer(signal.gaussian(8 * round(sig2) + 1, sig2), signal.gaussian(8 * round(sig2) + 1, sig2))\n",
    "            kernel1 = kernel / np.sum(kernel)\n",
    "    \n",
    "            # conv_list = []\n",
    "            # for k in range(data.shape[2]):\n",
    "            #     cut_data_k = data[:, :, k]\n",
    "            #     lurred_k = signal.fftconvolve(cut_data_k, kernel1, mode=\"same\")\n",
    "            #     conv_list.append(lurred_k[:, :, None])\n",
    "    \n",
    "            pi = signal.fftconvolve(data, kernel1, mode=\"same\")\n",
    "        else:\n",
    "            pi = data\n",
    "    else:\n",
    "        pi = data\n",
    "    return pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "derived-adapter",
   "metadata": {
    "id": "derived-adapter",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cut_data(data_, many_ind, cut_shape, r_hdu_header, g_hdu_header):\n",
    "    data_list = []\n",
    "    position_list_ = []\n",
    "    for i in many_ind:\n",
    "        x_min = i[1] - cut_shape/50\n",
    "        x_max = i[1] + cut_shape+cut_shape/50\n",
    "        y_min = i[0] - cut_shape/50\n",
    "        y_max = i[0] + cut_shape+cut_shape/50\n",
    "        data_c = data_[int(y_min):int(y_max), int(x_min):int(x_max)].view()\n",
    "        \n",
    "        if np.max(data_c) == np.max(data_c): # NaNの確認\n",
    "            flag = True\n",
    "            dim_data = []\n",
    "            for dim in range(data_c.shape[2]):\n",
    "                non_zero_count = np.count_nonzero(data_c[:,:,dim]) # 0が入っていないか？\n",
    "                \n",
    "                if non_zero_count==data_c.shape[0]*data_c.shape[1]:\n",
    "                    d = copy.deepcopy(data_c)\n",
    "                    d = median_filter(d[:,:,dim], size=3) # ノイズ除去\n",
    "                    if dim == 0: # resize時（大きい画像→小さい画像）のエイリアシングを考慮するためのconvolution\n",
    "                        dim_data.append(conv(300, sig1_r, d)[:,:,None])\n",
    "                    elif dim == 1:\n",
    "                        dim_data.append(conv(300, sig1_g, d)[:,:,None])\n",
    "                    pass\n",
    "                else:\n",
    "                    flag = False\n",
    "            if flag:\n",
    "                d = np.concatenate(dim_data, axis=2)\n",
    "                d = d[int(cut_shape/52):int(cut_shape*51/52), int(cut_shape/52):int(cut_shape*51/52)]\n",
    "                d = norm_res(d, r_hdu_header['CDELT1']*3600, g_hdu_header['CDELT1']*3600)\n",
    "                data_list.append(d)\n",
    "                position_list_.append([int(y_min)+int(cut_shape/50), int(x_min)+int(cut_shape/50)])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return data_list, position_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3090e38-4d4e-4dbe-903d-33d64efb4b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FWHM in pixels: 2.4455\n",
      "Calculated obj_sig: 1.0385\n"
     ]
    }
   ],
   "source": [
    "# --- 入力値 ---\n",
    "fwhm_arcsec = 0.269  # F770WのFWHM (秒角)\n",
    "pixel_scale = 0.11   # MIRIのピクセルスケール (秒角/ピクセル)\n",
    "\n",
    "# --- 計算 ---\n",
    "# 1. FWHMをピクセル単位へ変換\n",
    "fwhm_pixels = fwhm_arcsec / pixel_scale\n",
    "\n",
    "# 2. FWHM(ピクセル)を標準偏差σへ変換\n",
    "obj_sig = fwhm_pixels / (2 * (2 * np.log(2))**(1/2))\n",
    "\n",
    "print(f\"FWHM in pixels: {fwhm_pixels:.4f}\")\n",
    "print(f\"Calculated obj_sig: {obj_sig:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identical-dinner",
   "metadata": {
    "id": "identical-dinner"
   },
   "outputs": [],
   "source": [
    "# sig1_g = (0.269/0.11)/(2*(2*np.log(2))**(1/2))\n",
    "# sig1_r = (0.674/0.11)/(2*(2*np.log(2))**(1/2))\n",
    "\n",
    "sig1_g = (0.3/0.11)/(2*(2*np.log(2))**(1/2))\n",
    "sig1_r = (0.7/0.11)/(2*(2*np.log(2))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d50fe6c-1d9b-4c13-af00-ccfc78e324a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7023875463709697"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3nil78esDX4J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 1715,
     "status": "ok",
     "timestamp": 1698910973830,
     "user": {
      "displayName": "Astrolab OPU",
      "userId": "04256401714434573598"
     },
     "user_tz": -540
    },
    "id": "3nil78esDX4J",
    "outputId": "fbbbe681-75ec-47f6-ff89-393d31a57bed"
   },
   "outputs": [],
   "source": [
    "# api = wandb.Api()\n",
    "# artifact = api.artifact(\"galactic_bubble/search_BestModel_SpitzerBubblePaper2/training_log:v20\")\n",
    "# artifact.download(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "racial-strategy",
   "metadata": {
    "id": "racial-strategy",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net_w = SSD()\n",
    "net_weights = torch.load(\n",
    "    'training_log:v20/earlystopping.pth')\n",
    "net_w.load_state_dict(net_weights['model_state_dict'])\n",
    "del net_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vital-cream",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1698910980261,
     "user": {
      "displayName": "Astrolab OPU",
      "userId": "04256401714434573598"
     },
     "user_tz": -540
    },
    "id": "vital-cream",
    "outputId": "6935e747-4c8f-4647-c933-2fe53c850a1f",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (vgg): ModuleList(\n",
       "    (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU()\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU()\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU()\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU()\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU()\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU()\n",
       "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "    (32): ReLU()\n",
       "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (34): ReLU()\n",
       "  )\n",
       "  (extras): ModuleList(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  )\n",
       "  (L2Norm): L2Norm()\n",
       "  (loc): ModuleList(\n",
       "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conf): ModuleList(\n",
       "    (0): Conv2d(512, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Conv2d(1024, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (2): Conv2d(512, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(torch.device(\"cuda:0\") if torch.cuda.is_available() else 'cpu')\n",
    "net_w.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-rhythm",
   "metadata": {
    "id": "living-rhythm"
   },
   "source": [
    "#### 切り出すインデックスを計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "veterinary-workplace",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1698910980261,
     "user": {
      "displayName": "Astrolab OPU",
      "userId": "04256401714434573598"
     },
     "user_tz": -540
    },
    "id": "veterinary-workplace",
    "outputId": "384297c8-37b8-4b9d-ebe5-c5cd0a10d72c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size_list = [25, 50, 75, 100, 125, 150, 200, 250, 300, 400, 500, 600, 700, 800, 900, 950]\n",
    "size_list = [25, 50, 75, 100, 150, 300, 600]\n",
    "# size_list = [600]\n",
    "batch_list = [3000, 1000, 500, 100, 30, 30, 30]\n",
    "# batch_list = [30]\n",
    "len(size_list), len(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1ca4c6b-cc99-4a55-bbc0-82e7bff39715",
   "metadata": {
    "id": "e1ca4c6b-cc99-4a55-bbc0-82e7bff39715"
   },
   "outputs": [],
   "source": [
    "detect = Detect(nms_thresh=0.45, top_k=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db512fd4-8144-455f-bcbe-9cc7708cea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies=[\"ic5332\", \"ngc0628\", \"ngc1087\", \"ngc1300\", \"ngc1365\", \"ngc1385\", \"ngc1433\", \"ngc1512\",\n",
    "          \"ngc1566\", \"ngc1672\", \"ngc2835\", \"ngc3351\", \"ngc3627\", \"ngc4254\", \"ngc4303\", \"ngc4321\", \n",
    "          \"ngc4535\", \"ngc5068\", \"ngc7496\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f51fd842-ec35-435d-b360-c0a8821bab7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ic5332'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gal_name = galaxies[0]\n",
    "gal_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0286424c-d9b7-4876-a3d3-267f366852e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/elmegreen/jupyter/research/Bubble_detection/Paper2/phangs_jwst/Detection_Model/SN_Model_New_Norm/analyse_JWST/noise/smooth_fits/ic5332/hlsp_phangs-jwst_jwst_miri_ic5332_f770w_v1p1_img_subtract_0.1.smooth0.3arcsec.fits']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f6f346-bc8f-4ab8-b2d1-3791a8874dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITSファイルのパスを取得\n",
    "r_path = glob.glob(\n",
    "    f'/home/elmegreen/jupyter/research/Bubble_detection/Paper2/phangs_jwst/Detection_Model/SN_Model_New_Norm/analyse_JWST/noise/smooth_fits/{gal_name}/*f2100w*0.25.smooth0.7arcsec.fits')\n",
    "g_path = glob.glob(\n",
    "    f'/home/elmegreen/jupyter/research/Bubble_detection/Paper2/phangs_jwst/Detection_Model/SN_Model_New_Norm/analyse_JWST/noise/smooth_fits/{gal_name}/*f770w*0.1.smooth0.3arcsec.fits')\n",
    "\n",
    "if not r_path or not g_path:\n",
    "    print(f\"警告: {gal_name} のFITSファイルが見つかりません。スキップします。\")\n",
    "    pass\n",
    "\n",
    "# FITSデータの読み込みと前処理\n",
    "r_hdu = astropy.io.fits.open(r_path[0])[0]\n",
    "g_hdu = astropy.io.fits.open(g_path[0])[0]\n",
    "\n",
    "r_hdu_data = r_hdu.data\n",
    "# lower_bound = np.percentile(r_hdu_data, 1)\n",
    "# upper_bound = np.percentile(r_hdu_data, 99)\n",
    "# r_hdu_data = np.clip(r_hdu_data, lower_bound, upper_bound)\n",
    "r_hdu_data[r_hdu_data == 0.0] = np.nan\n",
    "\n",
    "g_hdu_data = g_hdu.data\n",
    "# lower_bound = np.percentile(g_hdu_data, 1)\n",
    "# upper_bound = np.percentile(g_hdu_data, 99)\n",
    "# g_hdu_data = np.clip(g_hdu_data, lower_bound, upper_bound)\n",
    "g_hdu_data[g_hdu_data == 0.0] = np.nan\n",
    "# data_ = np.concatenate([remove_nan(r_hdu_data)[:, :, None],\n",
    "#                         remove_nan(g_hdu_data)[:, :, None]], axis=2)\n",
    "data_ = np.concatenate([r_hdu_data[:, :, None],\n",
    "                        g_hdu_data[:, :, None]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21cc06e7-6a61-4143-82e8-81638bb4d6f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 開始: ic5332 の処理 ===============\n",
      "\n",
      "  -> 現在の処理サイズ: 25x25, バッチ分割数: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 25: 100%|█████████████████████████████████████████████████████████████| 2999/2999 [01:57<00:00, 25.44it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 50x50, バッチ分割数: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 50: 100%|███████████████████████████████████████████████████████████████| 999/999 [00:25<00:00, 39.08it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 75x75, バッチ分割数: 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 75: 100%|███████████████████████████████████████████████████████████████| 499/499 [00:12<00:00, 39.71it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 100x100, バッチ分割数: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 100: 100%|████████████████████████████████████████████████████████████████| 99/99 [00:13<00:00,  7.16it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 150x150, バッチ分割数: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 150: 100%|████████████████████████████████████████████████████████████████| 29/29 [00:08<00:00,  3.24it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 300x300, バッチ分割数: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 300: 100%|████████████████████████████████████████████████████████████████| 29/29 [00:01<00:00, 17.42it/s]/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  -> 現在の処理サイズ: 600x600, バッチ分割数: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  [推論中] Galaxy: ic5332, Size: 600: 100%|████████████████████████████████████████████████████████████████| 29/29 [00:00<00:00, 35.92it/s]/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== 完了: ic5332 の処理 ===============\n",
      "処理時間: 3.02 分\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"=============== 開始: {gal_name} の処理 ===============\")\n",
    "os.makedirs(f'result/{gal_name}/', exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# 異なる画像サイズでループ処理\n",
    "for size_index, size in enumerate(size_list):\n",
    "    bb = batch_list[size_index]\n",
    "    print(f\"\\n  -> 現在の処理サイズ: {size}x{size}, バッチ分割数: {bb}\")\n",
    "    \n",
    "    # ----------------- indexの計算 ----------------- #\n",
    "    cut_shape = (size, size)\n",
    "    fragment = 3\n",
    "    l = []\n",
    "    slide_pix = (int(round(cut_shape[0] / fragment)), int(round(cut_shape[1] / fragment)))    \n",
    "    shape = data_.shape\n",
    "    x_num = int(shape[1] / slide_pix[1]) - 1\n",
    "    y_num = int(shape[0] / slide_pix[0]) - 1\n",
    "    x_idx = np.arange(cut_shape[1] / 5, slide_pix[1] * x_num, slide_pix[1])\n",
    "    y_idx = np.arange(cut_shape[0] / 5, slide_pix[0] * y_num, slide_pix[0])\n",
    "    x_ind, y_ind = np.meshgrid(x_idx, y_idx)\n",
    "    \n",
    "    for x, y in zip(x_ind.ravel(), y_ind.ravel()):\n",
    "        l.append([y, x])\n",
    "    ind = np.array(l)\n",
    "    # ------------------------------------------------- #\n",
    "    \n",
    "    # ----------------- 推論 (infer) ----------------- #\n",
    "    result, position = [], []\n",
    "    result_filename = f'result/{gal_name}/result_ring_select_csize{cut_shape[0]}.npy'\n",
    "    if os.path.exists(result_filename):\n",
    "        os.remove(result_filename)\n",
    "    batch = np.linspace(0, ind.shape[0], bb, dtype=int)\n",
    "    \n",
    "    # tqdmで進捗を表示\n",
    "    pbar = tqdm(range(len(batch) - 1))\n",
    "    for i in pbar:\n",
    "        pbar.set_description(f\"  [推論中] Galaxy: {gal_name}, Size: {size}\")\n",
    "        \n",
    "        # indをバッチサイズに分割し、データを切り出して推論\n",
    "        cut_ind = ind[batch[i]:batch[i+1]]\n",
    "        data_list, p_list = cut_data(data_, cut_ind, cut_shape[0], r_hdu.header, g_hdu.header)\n",
    "        if len(data_list) == 0:\n",
    "            continue\n",
    "\n",
    "        p_data = torch.from_numpy(np.array(data_list).astype(np.float32))\n",
    "        pp_data = p_data.permute(0, 3, 1, 2)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            net_w.eval()\n",
    "            pp_data = pp_data.to(device)\n",
    "            output, decoded_box = net_w(pp_data)\n",
    "            detections = detect(*output)\n",
    "            position.append(p_list)\n",
    "            \n",
    "            # 結果の保存\n",
    "            detections_cpu = detections.to('cpu').detach().numpy().copy()\n",
    "            if size == 25: \n",
    "                with NpyAppendArray(result_filename) as npaa:\n",
    "                    npaa.append(detections_cpu)\n",
    "            else:\n",
    "                result.append(detections_cpu)\n",
    "\n",
    "    if not position:\n",
    "        print(f\"    -> サイズ {size} では有効なデータがなかったため、結果ファイルは作成されませんでした。\")\n",
    "        continue\n",
    "\n",
    "    position = np.concatenate(position)\n",
    "    np.save(f'result/{gal_name}/position_ring_select_csize{cut_shape[0]}.npy', position)\n",
    "\n",
    "    if size != 25 and result:\n",
    "        result = np.concatenate(result)\n",
    "        np.save(result_filename, result)\n",
    "    # ------------------------------------------------- #\n",
    "\n",
    "end_time = time.time()\n",
    "total_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"\\n=============== 完了: {gal_name} の処理 ===============\")\n",
    "print(f\"処理時間: {total_time_minutes:.2f} 分\")\n",
    "print(\"=\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c844ea3-2db9-4c69-98bb-b016b87e893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwhm = (600 / 300) * 2\n",
    "sig3 = fwhm / (2 * (2 * np.log(2)) ** (1 / 2))\n",
    "sig1_r = (0.674/0.11)/(2*(2*np.log(2))**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01f999ff-eaba-4fc7-88f7-ffbf4968e8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6986436005760381, 2.6020131517914766)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig3, sig1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0bc92bb-18f7-45f5-a039-f488fdb360b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.344221271625419"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sig3**2 - obj_sig**2) ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35689730-45a1-44e4-a704-90cdd5b52bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
